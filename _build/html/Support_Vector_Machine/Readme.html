
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Support vector machine &#8212; Machine learning book</title>
    
  <link rel="stylesheet" href="../_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.bfb7730f9caf2ec0b46a44615585038c.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Underfitting Overfitting" href="../Underfitting%20Overfitting/README.html" />
    <link rel="prev" title="Standardization and normalization" href="../Standardization_Normalization/README.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo_1.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine learning book</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Machine learning Knowledge Project
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Topics
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Contributors.html">
   Contributors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Cluster%20Validation/Readme.html">
   Cluster Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Convolution%20Neural%20Networks/Readme.html">
   Convolution Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Cross-Validation/Readme.html">
   Cross-Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DataScience101/readme.html">
   DataScience101
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Decision_Trees/Readme.html">
   Decision Trees Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Ensemble%20learning/Readme.html">
   Ensemble
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Generative%20Adversarial%20Networks/README.html">
   GANs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Genetic_Algorithms/Readme.html">
   Genetic Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../harmful%20object%20detection/README.html">
   Harmful Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../K-means/Readme.html">
   Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../K-means/Readme.html#k-means">
   K-means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Naive%20Bayes%20Classifier/Readme.html">
   Naive Bayes Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Nearest_neighbours/Readme.html">
   K-Nearest neighbor clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Normalization/Readme.html">
   Data Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Outliers/Readme.html">
   Outliers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Reinforcement%20Learning/README.html">
   Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Reinforcement%20Learning/README.html#genetic-algorithm-for-reinforcement-learning">
   Genetic Algorithm for Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Stacking/README.html">
   Stacking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Standardization_Normalization/README.html">
   Standardization and normalization
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Support vector machine
   <svm>
   </svm>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Underfitting%20Overfitting/README.html">
   Underfitting Overfitting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../XGBoost/Readme.html">
   XGBoost
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Support_Vector_Machine/Readme.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications-usage-to-solve-real-world-problems">
   Applications/Usage to solve real-world problems:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#large-blue-diamond-how-does-support-vector-machine-work">
   :large_blue_diamond: How does Support vector machine work?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linearly-separable-data">
     1. Linearly Separable Data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linearly-non-separable-data">
     2. Linearly Non-separable Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#large-blue-diamond-advantages-of-support-vector-machine">
   :large_blue_diamond: Advantages of Support vector machine
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#large-blue-diamond-disadvantages-of-support-vector-machine">
   :large_blue_diamond: Disadvantages of Support vector machine
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#do-you-want-to-learn-more-click-here">
     Do you want to learn more? Click here.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm-support-vector-machine-some-more-information-about-svm-including-real-world-problems">
     SVM(Support Vector Machine): some more information about svm including real world problems
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="support-vector-machine-svm">
<h1>Support vector machine <SVM><a class="headerlink" href="#support-vector-machine-svm" title="Permalink to this headline">¶</a></h1>
<p>A support vector machine (SVM) is machine learning algorithm that analyzes data for classification and regression analysis. SVM is a supervised learning method that looks at data and sorts it into one of two categories. An SVM outputs a map of the sorted data with the margins between the two as far apart as possible. SVMs are used in text categorization, image classification, handwriting recognition and in the sciences.</p>
<p>A support vector machine is also known as a support vector network (SVN). Also is a supervised learning algorithm that sorts data into two categories. It is trained with a series of data already classified into two categories, building the model as it is initially trained. The task of an SVM algorithm is to determine which category a new data point belongs in. This makes SVM a kind of non-binary linear classifier. It was introduced in the late 1990s and successfully applied to many engineering related applications</p>
<p>An SVM algorithm should not only place objects into categories, but have the margins between them on a graph as wide as possible.</p>
<p>Some applications of SVM include:</p>
<ul class="simple">
<li><p>Text and hypertext classification</p></li>
<li><p>Image classification</p></li>
<li><p>Recognizing handwritten characters</p></li>
<li><p>Biological sciences, including protein classification</p></li>
</ul>
<p><img alt="SVM GIF" src="../_images/gif.gif" /></p>
<p>In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.</p>
<p>When data are unlabelled, supervised learning is not possible, and an unsupervised learning approach is required, which attempts to find natural clustering of the data to groups, and then map new data to these formed groups. The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data, and is one of the most widely used clustering algorithms in industrial applications.</p>
<p><img alt="SVM GIF 2" src="Support_Vector_Machine\images/gif2.gif" /></p>
<div class="section" id="applications-usage-to-solve-real-world-problems">
<h2>Applications/Usage to solve real-world problems:<a class="headerlink" href="#applications-usage-to-solve-real-world-problems" title="Permalink to this headline">¶</a></h2>
<p>:triangular_flag_on_post: SVMs are helpful in text and hypertext categorization, as their application can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings. Some methods for shallow semantic parsing are based on support vector machines.</p>
<p>:triangular_flag_on_post: Classification of images can also be performed using SVMs. Experimental results show that SVMs achieve significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback. This is also true for image segmentation systems, including those using a modified version SVM that uses the privileged approach as suggested by Vapnik.</p>
<p>:triangular_flag_on_post: Classification of satellite data like SAR data using supervised SVM.</p>
<p>:triangular_flag_on_post: Hand-written characters can be recognized using SVM.</p>
<p>:triangular_flag_on_post: The SVM algorithm has been widely applied in the biological and other sciences. They have been used to classify proteins with up to 90% of the compounds classified correctly. Permutation tests based on SVM weights have been suggested as a mechanism for interpretation of SVM models. Support-vector machine weights have also been used to interpret SVM models in the past. Posthoc interpretation of support-vector machine models in order to identify features used by the model to make predictions is a relatively new area of research with special significance in the biological sciences.</p>
</div>
<div class="section" id="large-blue-diamond-how-does-support-vector-machine-work">
<h2>:large_blue_diamond: How does Support vector machine work?<a class="headerlink" href="#large-blue-diamond-how-does-support-vector-machine-work" title="Permalink to this headline">¶</a></h2>
<div class="section" id="linearly-separable-data">
<h3>1. Linearly Separable Data<a class="headerlink" href="#linearly-separable-data" title="Permalink to this headline">¶</a></h3>
<p>Let us understand the working of SVM by taking an example where we have two classes that are shown is the below image which are a class A: Circle &amp; class B: Triangle. Now, we want to apply the SVM algorithm and find out the best hyperplane that divides the both classes.</p>
<p><img alt="Linear Separable Data" src="../_images/1.JPG" /></p>
<p><img alt="Linear Separable Data" src="../_images/2.JPG" /></p>
<p>SVM takes all the data points in consideration and gives out a line that is called ‘Hyperplane’ which divides both the classes. This line is termed as ‘Decision boundary’. Anything that falls in circle class will belong to the  class A and vice-versa.</p>
<p><img alt="Linear Separable Data" src="../_images/3.JPG" /></p>
<p>There can be many hyperplanes that you can see but the best hyper plane that divides the two classes would be the hyperplane having a large distance from the hyperplane from both the classes. That is the main motive of SVM to find such best hyperplanes.</p>
<p>There can be different dimensions which solely depends upon the features we have. It is tough to visualize when the features are more than 3.</p>
<p><img alt="Linear Separable Data" src="../_images/4.JPG" /></p>
<p>Consider we have two classes that are red and yellow class A and B respectively. We need to find the best hyperplane between them that divides the two classes.</p>
<p><img alt="Linear Separable Data" src="../_images/5.JPG" /></p>
<p>Soft margin permits few of the above data points to get misclassified. Also,it tries to make the balance back and forth between finding a hyperplane that attempts to make less misclassifications and maximize the margin.</p>
</div>
<div class="section" id="linearly-non-separable-data">
<h3>2. Linearly Non-separable Data<a class="headerlink" href="#linearly-non-separable-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="Linearly Non-separable Data" src="../_images/6.JPG" /></p>
<p>If the data is non linearly separable as shown in the above figure then SVM makes use of kernel tricks to make it linearly separable. The concept of transformation of non-linearly separable data into linearly separable is called Cover’s theorem - “given a set of training data that is not linearly separable, with high probability it can be transformed into a linearly separable training set by projecting it into a higher-dimensional space via some non-linear transformation”. Kernel tricks help in projecting data point to the higher dimensional space by which they became relatively more easily separable in higher dimensional space.</p>
</div>
</div>
<div class="section" id="large-blue-diamond-advantages-of-support-vector-machine">
<h2>:large_blue_diamond: Advantages of Support vector machine<a class="headerlink" href="#large-blue-diamond-advantages-of-support-vector-machine" title="Permalink to this headline">¶</a></h2>
<p>:heavy_check_mark: Effective in high dimensional spaces.</p>
<p>:heavy_check_mark: Still effective in cases where number of dimensions is greater than the number of samples.</p>
<p>:heavy_check_mark: Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.</p>
<p>:heavy_check_mark: Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</p>
</div>
<div class="section" id="large-blue-diamond-disadvantages-of-support-vector-machine">
<h2>:large_blue_diamond: Disadvantages of Support vector machine<a class="headerlink" href="#large-blue-diamond-disadvantages-of-support-vector-machine" title="Permalink to this headline">¶</a></h2>
<p>:x: If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.</p>
<p>:x: SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).</p>
<div class="section" id="do-you-want-to-learn-more-click-here">
<h3>Do you want to learn more? Click here.<a class="headerlink" href="#do-you-want-to-learn-more-click-here" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Support_vector_machine#Computing_the_SVM_classifier">Support vector machine Wikipedia page</a></p>
<p>:arrow_lower_right: References:</p>
<p><a class="reference external" href="https://www.analyticssteps.com/blogs/how-does-support-vector-machine-algorithm-works-machine-learning">Link 1</a></p>
<p><a class="reference external" href="https://www.techopedia.com/definition/30364/support-vector-machine-svm">Link 2</a></p>
<p><a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html">Link 3</a></p>
<p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/B9780128113189000272">Link 4</a></p>
<p><a class="reference external" href="https://towardsdatascience.com/i-support-vector-machines-and-so-should-you-7af122b6748">Link 5</a></p>
</div>
<div class="section" id="svm-support-vector-machine-some-more-information-about-svm-including-real-world-problems">
<h3>SVM(Support Vector Machine): some more information about svm including real world problems<a class="headerlink" href="#svm-support-vector-machine-some-more-information-about-svm-including-real-world-problems" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf">Link 1</a></p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Support_Vector_Machine"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../Standardization_Normalization/README.html" title="previous page">Standardization and normalization</a>
    <a class='right-next' id="next-link" href="../Underfitting%20Overfitting/README.html" title="next page">Underfitting Overfitting</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Machine learning Knowledge Project<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.30270b6e4c972e43c488.js"></script>


    
  </body>
</html>