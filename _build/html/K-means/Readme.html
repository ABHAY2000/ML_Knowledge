
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Clustering &#8212; Machine learning book</title>
    
  <link rel="stylesheet" href="../_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.bfb7730f9caf2ec0b46a44615585038c.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Naive Bayes Classifier" href="../Naive%20Bayes%20Classifier/Readme.html" />
    <link rel="prev" title="Harmful Object Detection" href="../harmful%20object%20detection/README.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo_1.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine learning book</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Machine learning Knowledge Project
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Topics
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Contributors.html">
   Contributors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Cluster%20Validation/Readme.html">
   Cluster Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Convolution%20Neural%20Networks/Readme.html">
   Convolution Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Cross-Validation/Readme.html">
   Cross-Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DataScience101/readme.html">
   DataScience101
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Decision_Trees/Readme.html">
   Decision Trees Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Ensemble%20learning/Readme.html">
   Ensemble
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Generative%20Adversarial%20Networks/README.html">
   GANs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Genetic_Algorithms/Readme.html">
   Genetic Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../harmful%20object%20detection/README.html">
   Harmful Object Detection
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#k-means">
   K-means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Naive%20Bayes%20Classifier/Readme.html">
   Naive Bayes Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Nearest_neighbours/Readme.html">
   K-Nearest neighbor clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Normalization/Readme.html">
   Data Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Outliers/Readme.html">
   Outliers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Reinforcement%20Learning/README.html">
   Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Reinforcement%20Learning/README.html#genetic-algorithm-for-reinforcement-learning">
   Genetic Algorithm for Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Stacking/README.html">
   Stacking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Standardization_Normalization/README.html">
   Standardization and normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Support_Vector_Machine/Readme.html">
   Support vector machine
   <svm>
   </svm>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Underfitting%20Overfitting/README.html">
   Underfitting Overfitting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../XGBoost/Readme.html">
   XGBoost
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/K-means/Readme.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Clustering
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-means">
   K-means
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-blue-diamond-how-does-it-work">
     :large_blue_diamond: How does it work?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-blue-diamond-advantages-of-k-means">
     :large_blue_diamond: Advantages of k-means
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-blue-diamond-disadvantages-of-k-means">
     :large_blue_diamond: Disadvantages of k-means
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#do-you-want-to-learn-more-click-here">
       Do you want to learn more? Click here.
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="clustering">
<h1>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h1>
<p>Before talking especifically about the K-means, it’s good to know about the process of clustering. Each clustering algorithm comes in two variants: a class, that implements the fit method to learn the clusters on train data, and a function, that, given train data, returns an array of integer labels corresponding to the different clusters. For the class, the labels over the training data can be found in the labels_ attribute.</p>
</div>
<div class="section" id="k-means">
<h1>K-means<a class="headerlink" href="#k-means" title="Permalink to this headline">¶</a></h1>
<p>K Means is an algorithm for unsupervised clustering: that is, finding clusters in data based on the data attributes alone (not the labels).</p>
<p>K Means is a relatively easy-to-understand algorithm. It searches for cluster centers which are the mean of the points within them, such that every point is closest to the cluster center it is assigned to.</p>
<p>The KMeans algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares (see below). This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.</p>
<p><img alt="K-means example" src="../_images/k-means.gif" /></p>
<p>The k-means algorithm divides a set of N samples X  into  K disjoint clusters C, each described by the mean uj
of the samples in the cluster. The means are commonly called the cluster “centroids”; note that they are not, in general, points from X , although they live in the same space.</p>
<p>The K-means algorithm aims to choose centroids that minimise the inertia, or within-cluster sum-of-squares criterion:</p>
<p>Inertia can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</p>
<p>-&gt; Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.</p>
<p>-&gt; Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”). Running a dimensionality reduction algorithm such as Principal component analysis (PCA) prior to k-means clustering can alleviate this problem and speed up the computations.</p>
<p>The k-means clustering algorithm attempts to split a given anonymous data set (a set containing no information as to class identity) into a fixed number (k) of clusters.</p>
<p><img alt="A comparison of the clustering algorithms in scikit-learn" src="../_images/comparation.png" /></p>
<div class="section" id="large-blue-diamond-how-does-it-work">
<h2>:large_blue_diamond: How does it work?<a class="headerlink" href="#large-blue-diamond-how-does-it-work" title="Permalink to this headline">¶</a></h2>
<p>Initially k number of so called centroids are chosen. A centroid is a data point (imaginary or real) at the center of a cluster. In Praat each centroid is an existing data point in the given input data set, picked at random, such that all centroids are unique (that is, for all centroids ci and cj, ci ≠ cj). These centroids are used to train a kNN classifier. The resulting classifier is used to classify (using k = 1) the data and thereby produce an initial randomized set of clusters. Each centroid is thereafter set to the arithmetic mean of the cluster it defines. The process of classification and centroid adjustment is repeated until the values of the centroids stabilize. The final centroids will be used to produce the final classification/clustering of the input data, effectively turning the set of initially anonymous data points into a set of data points, each with a class identity.</p>
</div>
<div class="section" id="large-blue-diamond-advantages-of-k-means">
<h2>:large_blue_diamond: Advantages of k-means<a class="headerlink" href="#large-blue-diamond-advantages-of-k-means" title="Permalink to this headline">¶</a></h2>
<p>Relatively simple to implement.</p>
<p>:heavy_check_mark: Scales to large data sets.</p>
<p>:heavy_check_mark: Guarantees convergence.</p>
<p>:heavy_check_mark: Can warm-start the positions of centroids.</p>
<p>:heavy_check_mark: Easily adapts to new examples.</p>
<p>:heavy_check_mark: Generalizes to clusters of different shapes and sizes, such as elliptical clusters.</p>
</div>
<div class="section" id="large-blue-diamond-disadvantages-of-k-means">
<h2>:large_blue_diamond: Disadvantages of k-means<a class="headerlink" href="#large-blue-diamond-disadvantages-of-k-means" title="Permalink to this headline">¶</a></h2>
<p>:x: Choosing k manually.</p>
<p>:x: Being dependent on initial values.</p>
<p>:x: Clustering data of varying sizes and density.</p>
<p>:x: Clustering outliers.</p>
<p>:x: Scaling with number of dimensions.</p>
<div class="section" id="do-you-want-to-learn-more-click-here">
<h3>Do you want to learn more? Click here.<a class="headerlink" href="#do-you-want-to-learn-more-click-here" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">K-means Wikipedia page</a></p>
<p>:arrow_lower_right: References:</p>
<p><a class="reference external" href="https://github.com/jakevdp/sklearn_pycon2015/blob/master/notebooks/04.2-Clustering-KMeans.ipynb">Link 1</a></p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">Link 2</a></p>
<p><a class="reference external" href="https://www.fon.hum.uva.nl/praat/manual/k-means_clustering_1__How_does_k-means_clustering_work_.html#:~:text=The%20k%2Dmeans%20clustering%20algorithm,number%20(k)%20of%20clusters.&amp;text=A%20centroid%20is%20a%20data,the%20center%20of%20a%20cluster">Link 3</a></p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./K-means"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../harmful%20object%20detection/README.html" title="previous page">Harmful Object Detection</a>
    <a class='right-next' id="next-link" href="../Naive%20Bayes%20Classifier/Readme.html" title="next page">Naive Bayes Classifier</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Machine learning Knowledge Project<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.30270b6e4c972e43c488.js"></script>


    
  </body>
</html>